<!DOCTYPE html>
<html lang="en">

<head>
<title>ABconvergence</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/morris.js/0.5.1/morris.css">
<link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="static/css/social.css">
<script src="//ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/raphael/2.1.0/raphael-min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/morris.js/0.5.1/morris.min.js"></script>
<script src="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script type="text/javascript" src="static/js/plotResult.js"></script>

<style type="text/css">

body {
	/*background-image:url('static/css/bg.jpg');*/
	background-attachment:fixed;
	background-repeat: no-repeat;
	background-size: cover;
	padding-left: 10%;
	padding-right: 10%;
}

/* Remove the navbar's default margin-bottom and rounded borders */ 
    .navbar {
      color: red;
      /*margin-bottom: 0;
      border-radius: 0;*/
    }

    .error {
      color:red;
    }

    .navbar-custom,footer {
      background-color: #736E6D; 
    }

    .navbar-custom {
      color: white;
    }

    /* Set height of the grid so .sidenav can be 100% (adjust as needed) */
    .row.content {height: 450px}
    
    /* Set gray background color and 100% height */
    .sidenav {
      padding-top: 20px;
      background-color: #f1f1f1;
      height: 100%;
    }
    
    /* Set black background color, white text and some padding */
    footer {
      color: white;
      padding: 15px;
    }
    
    /* On small screens, set height to 'auto' for sidenav and grid */
    @media screen and (max-width: 767px) {
      .sidenav {
        height: auto;
        padding: 15px;
      }
      .row.content {height:auto;} 
    }
</style>
</head>

<!-- <body style="background-color:#FF0000;"> -->
<body>
<!--
<nav class="navbar navbar-inverse navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <a class="navbar-custom">Some ways to contact me for feedback:</a>
    </div>
    <div class="collapse navbar-collapse" id="myNavbar">
      <ul class="nav navbar-nav">
	<li><a id="github" href="https://github.com/Ranlot">GitHub</a></li>
        <li><a href="https://il.linkedin.com/in/laurent-boué-b7923853">LinkedIn</a></li>
      </ul>
    </div>
  </div>
</nav>-->

<div style="white-space:nowrap;text-align:left; background-color:orange;">
  <div style="display:inline-block;">
    Some ways to contact me for feedback:
  </div>
  <div style="display:inline-block;">
    <a href="https://github.com/Ranlot"><img src="static/css/GitHub_Logo.png" alt="GitHub" height="40px" /></a>
  </div>
 <div style="display:inline-block;">
    <a href="https://il.linkedin.com/in/laurent-boué-b7923853"><img src="https://simplesharebuttons.com/images/somacro/linkedin.png" height="40px" alt="LinkedIn" /></a>
  </div>
</div>


<div id="mainText" class="container-fluid text-center" style="margin-top:20px;">    
  <div class="content">
    <div class="text-left"> 

A more in-depth discussion along with source code and mathematical derivations can be found on this <a href="https://github.com/Ranlot/ab-testing">link</a>.

      <h3>Real-world hypothesis testing: a dependably treacherous adventure</h3>

<p>
From early 20th century beer tasting (the <a href="https://en.wikipedia.org/wiki/William_Sealy_Gosset">historical origin</a> of scientific AB tests by William Sealy Gosset at the Guinness Brewery) to modern day marketing and business intelligence running at scale all over the internet, hypothesis testing usually stands as a pillar upon which business decisions are made.  However, questions reagrding <i>"statistical significance"</i> inescapably and quickly manifest themselves when one tries to provide some interpretation of the results.  Barring an exceptionnally well-designed experimental design, a cloud of perplexed turbulence may start to emerge...  For example, simultaneous changes to the system (such as deployment of new features, seasonal changes, special case scenarios...) and their (perceived or real) correlations with each other are the usual scapegoats which may give real-world hypothesis testing its general air of murkiness when it comes to the interpretation of the results. 
</p>

<p> Our objective is to exemplify one specific (and not widely recognized) factor that contributes to the hazards of hypothesis testing: <b>slow convergence due to finite size-effects</b>.  (One may also use the calculator below in order to get quantitative insights into how to better design their experiments...)
</p>

<p> In order to see the importance of finite-size effects, let us consider a series of N repeated events where each individual event can only support 2 possible outcomes: "sucess" with some probability p* and "failure" with probability of 1-p*.  For concreteness, one may think of coin flip in which p* represents the probability of observing a specific side (p* &ne; 1/2 for biased coins).  Alternatively, business intelligence readers may consider p* as the probability to click on a web page.  Note that such a process is known as <a href="https://en.wikipedia.org/wiki/Bernoulli_trial">Bernoulli trials</a> and that its statistical properties are well known.  For example, one can easily see that the statistics eventually converge to a Gaussian distribution of mean value p* and of standard deviation proportional to N<sup>-1/2</sup> (decreasing as the inverse square root of the number of events).
</p>

<p> Now that we know how our events are generated, let us further assume that (perhaps through previous experience) we are already aware of some "baseline success rate" p0 against which we would like to test the performance of our experiment.  The traditional techique consists in measuring our "empirical sucess rate" p and subject it to a statistical significance test against p0 in order to extract a p-value. According to common practice, the statistical test is the so-called <a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing">"one-proportion test"</a> and p-values smaller than 0.05 are considered enough to declare the difference between p and p0 as indeed "statistically significant".  Here, it is crucial to realize that because of the finiteness of the number of events N, p is random variable which is only <b>on average</b> equal to the "true success rate" p*.  Unfortunately, one is rarely in a position to run mutliple realizations of the experiment and must usually be satisifed with a single value p of the empirical success rate whose deviation away from p* depend on the sample size N as explained above.  
</p>

<p> The important consequence is that the p-value obtained by the single test described above cannot be taken at face value since it is itself a random variable with a complicated statistical distribution.  Therefore, an interesting question becomes: Given a "baseline rate" p0, a "true success rate" p* &ge; p0, how many events N do we need until <b>our single test</b> would yield a significant conclusion (as it should) with probability of at least 0.95? Let us re-emphasize that the subtlety here is that we consider only a single empirical realization of the experiment and that as such its observed statstics may differ from that of its underlying generator.</p>

<p> Note that the tool below allows one to also investigate the opposite situation where p* &le; p0.  In this case, we may be interested to know how many events it takes such that the experiment would yield a significant result (clearly wrong here) with a probability of no more than 0.01.
</p>

<h3> Slow-convergence exposed: see for yourself </h3>

<p><i> Guide: Valid probabilities can only take values between 0 and 1 exclusive. For example, you can start with p* = 0.51 and p0 = 0.5 in order to see that one needs to wait 27,000 events in order to ensure that the probability of observing a significant result is at least 0.95.  Business intelligence readers may be more interested in numbers such as p* = 0.0042 and p0 = 0.004 typical of so called click-through rates.  In this case, it would take more than 1 million events even though in order to see a true improvement of 5% in performance.</i> </p>

  <form id="myForm" class="form-inline">
    <div class="form-group">
      <label for="pStar">p* = </label>
      <input type="text" class="form-control" name="pStar" placeholder="Choose a true success rate" size="21">
    </div>
    <div class="form-group">
      <label for="pBaseLine">p0 = </label>
      <input type="text" class="form-control" name="pBaseLine" placeholder="Choose a baseline rate" size="21">
    </div>
    <input type="submit" id="params_submit" class="btn btn-info" style="color: black; background-color: #FFFFC2; border-color: #000000;" value="Get required number of observations"/>
    <span class="error"></span>
  </form>

  <div class = "col-md-6 text-center"><div id="plotConv"></div></div>
  <div class = "col-md-6 text-center"><div id="plotHisto"></div></div>

  <div class="navbar-text" id="result"></div>

  <div class="navbar-text" id="graphExplanation">
    The red curve shows the evolution of the probability of observing a significant p-value as a function of the number of events.  The blue histogram shows the position of the baseline rate shown as a vertical green line compared to the probability density function of the empirical success rate p constructed from the underlying Binomial trials with true success rate p*.  Note that the standard deviation is selected by taking N = N*.
  </div>

</div>
</div> 
</div>


<!-- https://simplesharebuttons.com/html-share-buttons/ -->
<!-- download relevant buttons to local for efficiency and reliability -->

<footer class="container-fluid text-center">
<p>Share this:</p>
<div id="share-buttons">
	<!-- LinkedIn -->
     	<a href="http://www.linkedin.com/shareArticle?mini=true&amp;url=https://p-value-convergence.herokuapp.com/" target="_blank">
	<img src="https://simplesharebuttons.com/images/somacro/linkedin.png" alt="LinkedIn" />
     	</a>
	<!-- Facebook -->
	<a href="http://www.facebook.com/sharer.php?u=https://p-value-convergence.herokuapp.com/" target="_blank">
	<img src="https://simplesharebuttons.com/images/somacro/facebook.png" alt="Facebook" />
	</a>
	<!-- Twitter -->
	<a href="https://twitter.com/share?url=https://p-value-convergence.herokuapp.com/" target="_blank">
	<img src="https://simplesharebuttons.com/images/somacro/twitter.png" alt="Twitter" />
	</a>
</div>
</footer>

</body>
</html>
